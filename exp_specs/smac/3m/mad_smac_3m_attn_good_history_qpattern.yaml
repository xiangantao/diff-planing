meta_data:
  exp_name: "mad_smac"
  script_path: "run_scripts/train.py"
  num_workers: 2
  job_name: "{dataset}/qpattern123002-h_{horizon}-hh_{history_horizon}-{model}-r_{returns_scale}-guidew_{condition_guidance_w}-ctde_{decentralized_execution}"

variables:
  seed: [100]

  horizon: [4]
  history_horizon: [20]
  returns_scale: [20]
  dataset: ["3m-Good"]
  condition_guidance_w: [1.2]

constants:
  # misc
  seed: 100
  env_type: "smac"
  n_agents: 3
  use_action: True
  discrete_action: True
  residual_attn: True
  decentralized_execution: False
  use_zero_padding: False
  pred_future_padding: True
  use_ddim_sample: False
  n_ddim_steps: 15

  # model
  model: "models.SharedConvAttentionDeconv"
  diffusion: "models.GaussianDiffusion"
  share_inv: True
  n_diffusion_steps: 200
  action_weight: 10
  loss_weights: null
  loss_discount: 1
  use_return_to_go: True
  dim_mults: [1, 4, 8]
  returns_condition: True
  predict_epsilon: True
  calc_energy: False
  dim: 128
  hidden_dim: 256
  condition_dropout: 0.25
  condition_guidance_w: 1.2
  train_only_inv: False
  clip_denoised: True
  test_ret: 1.0
  renderer: "utils.SMACRenderer"

  # dataset
  loader: "datasets.SequenceDataset"
  normalizer: "CDFNormalizer"
  max_n_episodes: 50000
  preprocess_fns: []
  use_padding: True
  discount: 0.99
  max_path_length: 60
  termination_penalty: 0.0

  # training
  n_steps_per_epoch: 1000
  n_train_steps: 100000
  batch_size: 512
  learning_rate: 0.0005
  gradient_accumulate_every: 2
  ema_decay: 0.995
  log_freq: 1000
  save_freq: 100000
  sample_freq: 10000
  n_saves: 5
  save_parallel: False
  n_reference: 3
  save_checkpoints: True

  # eval
  evaluator: "utils.MADEvaluator"
  num_envs: 10
  num_eval: 100
  eval_freq: 2000

  # load checkpoint
  continue_training: True

  # ---------------- Q_pattern (obs-diffusion) ----------------
  use_q_pattern: True
  transition_q_lr: 0.0001
  pattern_q_lr: 0.0001
  transition_q_hidden_dim: 512
  q_pattern_latent_dim: 64
  q_pattern_hidden_dim: 512
  q_pattern_encoder_hidden_dim: 256

  rollout_every: 100
  rollout_ddim_steps: 15
  rollout_batch_size: 64
  rollout_use_cfg: True
  rollout_policy_weight: 0.01
  rollout_bc_weight: 0.1

  # warmup schedule: first pretrain transition_q, then warmup pattern_q, then enable rollout policy loss
  transition_q_pretrain_steps: 2000
  pattern_q_warmup_steps: 1000

  # cleaner evaluator logging
  log_episode_details: False


